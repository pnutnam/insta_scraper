{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install instaloader beautifulsoup4 requests pandas"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Configuration settings for Instagram scraper.\"\"\"\n",
        "\n",
        "# Instagram settings\n",
        "INSTAGRAM_USERNAME = None  # Optional: Set if you need to login\n",
        "INSTAGRAM_PASSWORD = None  # Optional: Set if you need to login\n",
        "\n",
        "# Scraping settings\n",
        "MAX_LINKS_TO_CHECK = 20  # Maximum number of links to check from Linktree\n",
        "REQUEST_TIMEOUT = 10  # Timeout for HTTP requests in seconds\n",
        "MAX_RETRIES = 3  # Maximum number of retries for failed requests\n",
        "\n",
        "# Link tree services to detect\n",
        "LINK_TREE_SERVICES = [\n",
        "    'linktr.ee',\n",
        "    'linktree.com',\n",
        "    'bio.link',\n",
        "    'beacons.ai',\n",
        "    'hoo.be',\n",
        "    'solo.to',\n",
        "    'allmylinks.com',\n",
        "    'carrd.co',\n",
        "    'taplink.cc',\n",
        "    'linkpop.com',\n",
        "    'shorby.com',\n",
        "    'campsite.bio',\n",
        "]\n",
        "\n",
        "# Social media platforms to detect\n",
        "SOCIAL_PLATFORMS = {\n",
        "    'linkedin': ['linkedin.com/in/', 'linkedin.com/company/'],\n",
        "    'facebook': ['facebook.com/', 'fb.com/', 'fb.me/'],\n",
        "    'twitter': ['twitter.com/', 'x.com/'],\n",
        "    'youtube': ['youtube.com/', 'youtu.be/'],\n",
        "    'tiktok': ['tiktok.com/@'],\n",
        "    'pinterest': ['pinterest.com/'],\n",
        "    'instagram': ['instagram.com/'],\n",
        "}\n",
        "\n",
        "# Output settings\n",
        "OUTPUT_CSV = 'customer_ledger.csv'\n",
        "OUTPUT_JSON = 'customer_ledger.json'\n",
        "\n",
        "# User agent for requests\n",
        "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Module for resolving Linktree and similar bio link pages.\"\"\"\n",
        "\n",
        "import logging\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import Dict, List, Optional\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LinkTreeResolver:\n",
        "    \"\"\"Resolves 'link in bio' pages to find actual business websites.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.headers = {'User-Agent': USER_AGENT}\n",
        "\n",
        "    def is_link_tree(self, url: str) -> bool:\n",
        "        \"\"\"\n",
        "        Check if a URL is a known link tree service.\n",
        "        \n",
        "        Args:\n",
        "            url: The URL to check\n",
        "            \n",
        "        Returns:\n",
        "            True if it's a link tree service, False otherwise\n",
        "        \"\"\"\n",
        "        if not url:\n",
        "            return False\n",
        "            \n",
        "        try:\n",
        "            domain = urlparse(url).netloc.lower()\n",
        "            # Remove 'www.' if present\n",
        "            if domain.startswith('www.'):\n",
        "                domain = domain[4:]\n",
        "                \n",
        "            for service in LINK_TREE_SERVICES:\n",
        "                if service in domain:\n",
        "                    return True\n",
        "            return False\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def resolve_url(self, url: str) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        Resolve a link tree URL to find contained links.\n",
        "        \n",
        "        Args:\n",
        "            url: The link tree URL to resolve\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with 'social_links' and 'website_links'\n",
        "        \"\"\"\n",
        "        results = {\n",
        "            'social_links': [],\n",
        "            'website_links': []\n",
        "        }\n",
        "\n",
        "        if not url:\n",
        "            return results\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers, timeout=REQUEST_TIMEOUT)\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            \n",
        "            # Find all links\n",
        "            for a in soup.find_all('a', href=True):\n",
        "                href = a['href']\n",
        "                if not href or href.startswith('#') or href.startswith('mailto:'):\n",
        "                    continue\n",
        "                    \n",
        "                # Classify link\n",
        "                if self._is_social_link(href):\n",
        "                    if href not in results['social_links']:\n",
        "                        results['social_links'].append(href)\n",
        "                else:\n",
        "                    # Avoid adding the link tree itself or empty links\n",
        "                    if href != url and href not in results['website_links']:\n",
        "                        results['website_links'].append(href)\n",
        "                        \n",
        "            # Limit number of links to check/return\n",
        "            results['website_links'] = results['website_links'][:MAX_LINKS_TO_CHECK]\n",
        "            \n",
        "            return results\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error resolving link tree {url}: {e}\")\n",
        "            return results\n",
        "\n",
        "    def _is_social_link(self, url: str) -> bool:\n",
        "        \"\"\"Check if a URL is a social media link.\"\"\"\n",
        "        try:\n",
        "            domain = urlparse(url).netloc.lower()\n",
        "            for platform, domains in SOCIAL_PLATFORMS.items():\n",
        "                for d in domains:\n",
        "                    # Simple check if the domain part of the config exists in the url\n",
        "                    # This is a basic check and can be improved\n",
        "                    clean_d = d.split('/')[0] # get just domain from \"linkedin.com/in/\"\n",
        "                    if clean_d in domain:\n",
        "                        return True\n",
        "            return False\n",
        "        except Exception:\n",
        "            return False\n"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Module for scraping Instagram profile bio links.\"\"\"\n",
        "\n",
        "import instaloader\n",
        "import logging\n",
        "from typing import Optional, Dict\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class InstagramScraper:\n",
        "    \"\"\"Scrapes Instagram profiles to extract bio links.\"\"\"\n",
        "    \n",
        "    def __init__(self, username: Optional[str] = None, password: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize Instagram scraper.\n",
        "        \n",
        "        Args:\n",
        "            username: Instagram username for login (optional)\n",
        "            password: Instagram password for login (optional)\n",
        "        \"\"\"\n",
        "        self.loader = instaloader.Instaloader()\n",
        "        self.username = username\n",
        "        self.password = password\n",
        "        self.logged_in = False\n",
        "        \n",
        "    def login(self) -> bool:\n",
        "        \"\"\"\n",
        "        Login to Instagram if credentials are provided.\n",
        "        \n",
        "        Returns:\n",
        "            True if login successful or not needed, False otherwise\n",
        "        \"\"\"\n",
        "        if not self.username or not self.password:\n",
        "            logger.info(\"No credentials provided, using public access\")\n",
        "            return True\n",
        "            \n",
        "        try:\n",
        "            self.loader.login(self.username, self.password)\n",
        "            self.logged_in = True\n",
        "            logger.info(\"Successfully logged in to Instagram\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to login to Instagram: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_profile_info(self, instagram_handle: str) -> Optional[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Get profile information from Instagram.\n",
        "        \n",
        "        Args:\n",
        "            instagram_handle: Instagram username (without @)\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with profile info including bio link, or None if failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Remove @ if present\n",
        "            handle = instagram_handle.lstrip('@')\n",
        "            \n",
        "            # Load profile\n",
        "            profile = instaloader.Profile.from_username(self.loader.context, handle)\n",
        "            \n",
        "            # Initialize resolver\n",
        "            \n",
        "            resolver = LinkTreeResolver()\n",
        "            \n",
        "            external_url = profile.external_url\n",
        "            resolved_links = {'social_links': [], 'website_links': []}\n",
        "            \n",
        "            if external_url and resolver.is_link_tree(external_url):\n",
        "                logger.info(f\"Detected link tree: {external_url}, resolving...\")\n",
        "                resolved_links = resolver.resolve_url(external_url)\n",
        "                logger.info(f\"Resolved {len(resolved_links['website_links'])} website links and {len(resolved_links['social_links'])} social links\")\n",
        "            \n",
        "            info = {\n",
        "                'username': profile.username,\n",
        "                'full_name': profile.full_name,\n",
        "                'bio': profile.biography,\n",
        "                'external_url': external_url,\n",
        "                'resolved_website_links': resolved_links['website_links'],\n",
        "                'resolved_social_links': resolved_links['social_links'],\n",
        "                'followers': profile.followers,\n",
        "                'following': profile.followees,\n",
        "                'is_business': profile.is_business_account,\n",
        "                'is_verified': profile.is_verified,\n",
        "            }\n",
        "            \n",
        "            logger.info(f\"Successfully scraped profile: {handle}\")\n",
        "            logger.info(f\"External URL: {info['external_url']}\")\n",
        "            \n",
        "            return info\n",
        "            \n",
        "        except instaloader.exceptions.ProfileNotExistsException:\n",
        "            logger.error(f\"Profile not found: {instagram_handle}\")\n",
        "            return None\n",
        "        except instaloader.exceptions.ConnectionException as e:\n",
        "            logger.error(f\"Connection error while fetching profile {instagram_handle}: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching profile {instagram_handle}: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def get_bio_link(self, instagram_handle: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Get the bio link from an Instagram profile.\n",
        "        \n",
        "        Args:\n",
        "            instagram_handle: Instagram username (without @)\n",
        "            \n",
        "        Returns:\n",
        "            Bio link URL or None if not found\n",
        "        \"\"\"\n",
        "        profile_info = self.get_profile_info(instagram_handle)\n",
        "        if profile_info:\n",
        "            return profile_info.get('external_url')\n",
        "        return None\n"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Usage Example\n",
        "\n",
        "# Initialize scraper\n",
        "# Note: For public profiles, login might not be strictly necessary but recommended for stability.\n",
        "# If you have credentials, set them in the config variables above or pass them here.\n",
        "scraper = InstagramScraper()\n",
        "scraper.login()\n",
        "\n",
        "# Test with a handle\n",
        "handle = \"linktr.ee\" # Example handle, or use a real one\n",
        "print(f\"Scraping profile: {handle}\")\n",
        "info = scraper.get_profile_info(handle)\n",
        "\n",
        "if info:\n",
        "    print(\"Found profile info:\")\n",
        "    print(f\"Username: {info['username']}\")\n",
        "    print(f\"Bio Link: {info['external_url']}\")\n",
        "    if info.get('resolved_website_links'):\n",
        "        print(\"Resolved Website Links:\", info['resolved_website_links'])\n",
        "    if info.get('resolved_social_links'):\n",
        "        print(\"Resolved Social Links:\", info['resolved_social_links'])\n",
        "else:\n",
        "    print(\"Failed to scrape profile.\")\n"
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}